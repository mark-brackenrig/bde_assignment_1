{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DateType, IntegerType, BooleanType, FloatType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/work/notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName('assignment_1') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('data/combined_cleaned_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+----------+------------+------------+---------------+-------------+-----+-------+----------+------------+---------------------+------------+------------+-----------+-------------------+-------------------+\n",
      "|VendorID|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_colour|        pickup_date|       dropoff_date|\n",
      "+--------+------------------+----------+------------+------------+---------------+-------------+-----+-------+----------+------------+---------------------+------------+------------+-----------+-------------------+-------------------+\n",
      "|       2|             false|         1|          66|          33|              5|         0.51|  0.5|    0.5|       0.7|         0.0|                  0.3|           6|           1|      green|2018-06-01 00:33:55|2018-06-01 00:36:13|\n",
      "|       2|             false|         1|          25|          49|              5|         1.97|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|           1|      green|2018-06-01 00:40:36|2018-06-01 00:49:46|\n",
      "|       2|             false|         1|          61|          49|              5|          1.4|  0.5|    0.5|       0.0|         0.0|                  0.3|         7.8|           2|      green|2018-06-01 00:57:12|2018-06-01 01:02:58|\n",
      "|       2|             false|         1|          49|          97|              1|         1.36|  0.5|    0.5|       0.0|         0.0|                  0.3|         8.3|           2|      green|2018-06-01 00:10:13|2018-06-01 00:16:27|\n",
      "|       1|             false|         1|          75|         127|              1|          7.9|  0.5|    0.5|       6.3|         0.0|                  0.3|        31.6|           1|      green|2018-06-01 00:32:08|2018-06-01 00:52:06|\n",
      "|       1|             false|         1|          36|         112|              2|          2.9|  0.5|    0.5|       2.0|         0.0|                  0.3|        14.3|           1|      green|2018-06-01 00:15:35|2018-06-01 00:27:44|\n",
      "|       1|             false|         1|         256|          49|              1|          2.6|  0.5|    0.5|      2.15|         0.0|                  0.3|       12.95|           1|      green|2018-06-01 00:49:03|2018-06-01 00:57:26|\n",
      "|       2|             false|         1|          25|          28|              2|        14.64|  0.5|    0.5|       0.0|         0.0|                  0.3|        46.3|           1|      green|2018-06-01 00:49:31|2018-06-01 01:38:02|\n",
      "|       1|             false|         1|         179|         179|              1|          0.9|  0.5|    0.5|       2.0|         0.0|                  0.3|         8.8|           1|      green|2018-06-01 00:16:57|2018-06-01 00:22:05|\n",
      "|       1|             false|         1|         179|         179|              2|          0.9|  0.5|    0.5|       2.0|         0.0|                  0.3|         8.8|           1|      green|2018-06-01 00:42:02|2018-06-01 00:46:15|\n",
      "|       1|             false|         1|           7|         129|              1|          2.0|  0.5|    0.5|       2.0|         0.0|                  0.3|        12.8|           1|      green|2018-06-01 00:11:58|2018-06-01 00:22:47|\n",
      "|       2|             false|         1|         212|          81|              1|         5.93|  0.5|    0.5|       0.0|         0.0|                  0.3|        19.3|           2|      green|2018-06-01 00:12:54|2018-06-01 00:23:29|\n",
      "|       1|             false|         1|         256|          17|              2|          1.1|  0.5|    0.5|      1.45|         0.0|                  0.3|        8.75|           1|      green|2018-06-01 00:22:02|2018-06-01 00:28:08|\n",
      "|       1|             false|         1|          80|         225|              1|          2.3|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.8|           2|      green|2018-06-01 00:37:58|2018-06-01 00:52:17|\n",
      "|       2|             false|         1|          41|         168|              1|         1.57|  0.5|    0.5|      1.86|         0.0|                  0.3|       11.16|           1|      green|2018-06-01 00:02:32|2018-06-01 00:11:05|\n",
      "|       2|             false|         1|         106|         257|              5|         2.58|  0.5|    0.5|       0.0|         0.0|                  0.3|        12.3|           2|      green|2018-06-01 00:59:23|2018-06-01 01:11:18|\n",
      "|       2|             false|         1|          33|         257|              1|         3.27|  0.5|    0.5|       0.0|         0.0|                  0.3|        13.8|           2|      green|2018-06-01 00:11:24|2018-06-01 00:25:46|\n",
      "|       2|             false|         1|         226|         229|              1|         2.99|  0.5|    0.5|       0.0|         0.0|                  0.3|        13.3|           2|      green|2018-06-01 00:09:20|2018-06-01 00:19:42|\n",
      "|       2|             false|         1|           7|         179|              1|         1.26|  0.5|    0.5|       0.0|         0.0|                  0.3|         7.3|           2|      green|2018-06-01 00:48:39|2018-06-01 00:53:05|\n",
      "|       2|             false|         1|           7|         223|              1|         1.54|  0.5|    0.5|       0.0|         0.0|                  0.3|         7.8|           2|      green|2018-06-01 00:57:37|2018-06-01 01:03:32|\n",
      "+--------+------------------+----------+------------+------------+---------------+-------------+-----+-------+----------+------------+---------------------+------------+------------+-----------+-------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: string (nullable = true)\n",
      " |-- store_and_fwd_flag: boolean (nullable = true)\n",
      " |-- RatecodeID: string (nullable = true)\n",
      " |-- PULocationID: string (nullable = true)\n",
      " |-- DOLocationID: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: float (nullable = true)\n",
      " |-- extra: float (nullable = true)\n",
      " |-- mta_tax: string (nullable = true)\n",
      " |-- tip_amount: float (nullable = true)\n",
      " |-- tolls_amount: float (nullable = true)\n",
      " |-- improvement_surcharge: string (nullable = true)\n",
      " |-- total_amount: string (nullable = true)\n",
      " |-- payment_type: string (nullable = true)\n",
      " |-- taxi_colour: string (nullable = true)\n",
      " |-- pickup_date: timestamp (nullable = true)\n",
      " |-- dropoff_date: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SQL Queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a. For each year and month:\n",
    "***i. What was the total number of trips***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT COUNT(*) as trips, MONTH(pickup_date) as month, YEAR(pickup_date) as year\n",
    "FROM combined_data\n",
    "GROUP BY MONTH(pickup_date), YEAR(pickup_date)\n",
    "ORDER BY YEAR(pickup_date) desc,  MONTH(pickup_date) desc\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+----+\n",
      "|   trips|month|year|\n",
      "+--------+-----+----+\n",
      "| 8857779|   12|2018|\n",
      "| 8802332|   11|2018|\n",
      "| 9531620|   10|2018|\n",
      "| 8706559|    9|2018|\n",
      "| 8515365|    8|2018|\n",
      "| 8534027|    7|2018|\n",
      "| 9453060|    6|2018|\n",
      "|10021377|    5|2018|\n",
      "|10105415|    4|2018|\n",
      "|10266415|    3|2018|\n",
      "| 9262273|    2|2018|\n",
      "| 9553631|    1|2018|\n",
      "|10414465|   12|2017|\n",
      "|10158994|   11|2017|\n",
      "|10694462|   10|2017|\n",
      "| 9827956|    9|2017|\n",
      "| 9289554|    8|2017|\n",
      "| 9503269|    7|2017|\n",
      "|10633460|    6|2017|\n",
      "|11161587|    5|2017|\n",
      "|11127959|    4|2017|\n",
      "|11453266|    3|2017|\n",
      "|10192088|    2|2017|\n",
      "|10780387|    1|2017|\n",
      "+--------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ii. Which weekday had the most trips?***\n",
    "For ease in the SQL statement, I have created columns for the relevant parts of the datetime. I could have used these functions within the SQL statement itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofweek\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = df.withColumn('week_day', dayofweek(F.col('pickup_date')))\n",
    "df = df.withColumn('month', month(F.col('pickup_date')))\n",
    "df = df.withColumn('year', year(F.col('pickup_date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select b1.trips,b2.week_day, b1.month,b1.year from\n",
    "(select max(b.trips) as trips, b.month, b.year  from \n",
    "    (SELECT COUNT(*) as trips, week_day,month, year\n",
    "FROM combined_data\n",
    "GROUP BY week_day,month, year) as b\n",
    "Group by b.month, b.year) as b1\n",
    "inner join (SELECT COUNT(*) as trips, week_day,month, year\n",
    "FROM combined_data\n",
    "GROUP BY week_day,month, year) as b2 \n",
    "on (b1.trips, b1.month,b1.year)=(b2.trips, b2.month,b2.year)\n",
    "ORDER BY b2.year desc,  b2.month desc\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+----+\n",
      "|  trips|week_day|month|year|\n",
      "+-------+--------+-----+----+\n",
      "|1508664|       7|   12|2018|\n",
      "|1524979|       6|   11|2018|\n",
      "|1577684|       4|   10|2018|\n",
      "|1472752|       7|    9|2018|\n",
      "|1488433|       4|    8|2018|\n",
      "|1456883|       3|    7|2018|\n",
      "|1645423|       6|    6|2018|\n",
      "|1745106|       5|    5|2018|\n",
      "|1523951|       2|    4|2018|\n",
      "|1811863|       6|    3|2018|\n",
      "|1464827|       6|    2|2018|\n",
      "|1628165|       4|    1|2018|\n",
      "|1831381|       6|   12|2017|\n",
      "|1743664|       4|   11|2017|\n",
      "|1676870|       3|   10|2017|\n",
      "|1725010|       6|    9|2017|\n",
      "|1606769|       5|    8|2017|\n",
      "|1529962|       7|    7|2017|\n",
      "|1855817|       5|    6|2017|\n",
      "|1861369|       4|    5|2017|\n",
      "|1969259|       7|    4|2017|\n",
      "|2034770|       6|    3|2017|\n",
      "|1616477|       7|    2|2017|\n",
      "|1701968|       3|    1|2017|\n",
      "+-------+--------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***iii. Which hour of the day had the most trips?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import year, month, dayofweek, hour\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "df = df.withColumn('hour', hour(F.col('pickup_date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select b1.trips,b2.hour, b1.month,b1.year from\n",
    "(select max(b.trips) as trips, b.month, b.year  from \n",
    "    (SELECT COUNT(*) as trips, hour,month, year\n",
    "FROM combined_data\n",
    "GROUP BY hour,month, year) as b\n",
    "Group by b.month, b.year) as b1\n",
    "inner join (SELECT COUNT(*) as trips,hour,month, year\n",
    "FROM combined_data\n",
    "GROUP BY hour,month, year) as b2 \n",
    "on (b1.trips, b1.month,b1.year)=(b2.trips, b2.month,b2.year)\n",
    "ORDER BY b2.year desc,  b2.month desc\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+----+\n",
      "| trips|hour|month|year|\n",
      "+------+----+-----+----+\n",
      "|551515|  18|   12|2018|\n",
      "|555520|  18|   11|2018|\n",
      "|612721|  18|   10|2018|\n",
      "|557282|  18|    9|2018|\n",
      "|553496|  18|    8|2018|\n",
      "|547694|  18|    7|2018|\n",
      "|591743|  18|    6|2018|\n",
      "|636948|  18|    5|2018|\n",
      "|661268|  18|    4|2018|\n",
      "|667507|  18|    3|2018|\n",
      "|614335|  18|    2|2018|\n",
      "|632957|  18|    1|2018|\n",
      "|647202|  18|   12|2017|\n",
      "|650704|  18|   11|2017|\n",
      "|684103|  18|   10|2017|\n",
      "|622207|  19|    9|2017|\n",
      "|588260|  18|    8|2017|\n",
      "|589087|  18|    7|2017|\n",
      "|656818|  18|    6|2017|\n",
      "|690046|  18|    5|2017|\n",
      "|697420|  18|    4|2017|\n",
      "|735218|  19|    3|2017|\n",
      "|673287|  18|    2|2017|\n",
      "|692726|  18|    1|2017|\n",
      "+------+----+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***iv. What was the average number of passengers?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT AVG(passenger_count), month,  year\n",
    "FROM combined_data\n",
    "GROUP BY  month, year\n",
    "ORDER BY year desc,  month desc\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----+\n",
      "|avg(passenger_count)|month|year|\n",
      "+--------------------+-----+----+\n",
      "|  1.5749735910096652|   12|2018|\n",
      "|  1.5589607390405178|   11|2018|\n",
      "|  1.5523811272375525|   10|2018|\n",
      "|  1.5698228197844866|    9|2018|\n",
      "|  1.5822324703638657|    8|2018|\n",
      "|  1.5859522122439969|    7|2018|\n",
      "|  1.5787771367155186|    6|2018|\n",
      "|   1.577745653117331|    5|2018|\n",
      "|  1.5817253423041013|    4|2018|\n",
      "|  1.5817686115357699|    3|2018|\n",
      "|  1.5763987954144734|    2|2018|\n",
      "|  1.5865468322986307|    1|2018|\n",
      "|   1.609397794317807|   12|2017|\n",
      "|  1.5904028489435076|   11|2017|\n",
      "|  1.5955872301009626|   10|2017|\n",
      "|  1.6032556515312035|    9|2017|\n",
      "|  1.6093790939801846|    8|2017|\n",
      "|  1.6151521123941668|    7|2017|\n",
      "|  1.5992691936585082|    6|2017|\n",
      "|  1.5952257506033864|    5|2017|\n",
      "|   1.601502935084502|    4|2017|\n",
      "|  1.5923528712246795|    3|2017|\n",
      "|  1.5986640813933317|    2|2017|\n",
      "|  1.6031179585667936|    1|2017|\n",
      "+--------------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***v. What was the average amount paid per trip (total_amount)?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT AVG(total_amount), month,  year\n",
    "FROM combined_data\n",
    "GROUP BY  month, year\n",
    "ORDER BY year desc,  month desc\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+-----+----+\n",
      "|avg(CAST(total_amount AS DOUBLE))|month|year|\n",
      "+---------------------------------+-----+----+\n",
      "|                 16.5143992903445|   12|2018|\n",
      "|                 16.7899788057978|   11|2018|\n",
      "|               16.947767601974277|   10|2018|\n",
      "|               16.808269310715303|    9|2018|\n",
      "|                16.57538040690682|    8|2018|\n",
      "|                16.54223904844393|    7|2018|\n",
      "|               16.628314385004405|    6|2018|\n",
      "|               16.755300685929303|    5|2018|\n",
      "|                16.27453824528984|    4|2018|\n",
      "|               15.879032786926034|    3|2018|\n",
      "|               15.366286035642922|    2|2018|\n",
      "|               15.367568301570396|    1|2018|\n",
      "|                16.01089971694115|   12|2017|\n",
      "|               16.305887479662697|   11|2017|\n",
      "|               16.554977008867855|   10|2017|\n",
      "|               16.535440411042156|    9|2017|\n",
      "|               16.289620089609635|    8|2017|\n",
      "|               16.190408010335542|    7|2017|\n",
      "|               16.449984144309273|    6|2017|\n",
      "|                16.53947411054859|    5|2017|\n",
      "|               16.134605752127648|    4|2017|\n",
      "|                15.98098345681226|    3|2017|\n",
      "|               15.448528459475417|    2|2017|\n",
      "|               15.338525530874705|    1|2017|\n",
      "+---------------------------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***vi. What was the average amount paid per passenger (total_amount)?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT AVG(total_amount/passenger_count) as cost_per_passenger, month,  year\n",
    "FROM combined_data\n",
    "GROUP BY  month, year\n",
    "ORDER BY year desc,  month desc\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+----+\n",
      "|cost_per_passenger|month|year|\n",
      "+------------------+-----+----+\n",
      "|13.549758973470507|   12|2018|\n",
      "|13.920740461645034|   11|2018|\n",
      "|14.085970087706691|   10|2018|\n",
      "|13.913103221285503|    9|2018|\n",
      "|13.676620190797392|    8|2018|\n",
      "| 13.63917960186089|    7|2018|\n",
      "|13.734457836029895|    6|2018|\n",
      "|13.857840071732484|    5|2018|\n",
      "|13.420629305781736|    4|2018|\n",
      "|13.118663687856754|    3|2018|\n",
      "|12.744973055655787|    2|2018|\n",
      "|12.705123826288716|    1|2018|\n",
      "|13.084823013559964|   12|2017|\n",
      "|13.452684448129276|   11|2017|\n",
      "|13.656854595631154|   10|2017|\n",
      "|13.610389402410114|    9|2017|\n",
      "|13.378996400182738|    8|2017|\n",
      "|13.266759951874388|    7|2017|\n",
      "|13.585708949705127|    6|2017|\n",
      "| 13.63220577948025|    5|2017|\n",
      "|13.296277392036433|    4|2017|\n",
      "|13.226725031818637|    3|2017|\n",
      "|12.746678349579957|    2|2017|\n",
      "|12.648085591722742|    1|2017|\n",
      "+------------------+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show(24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. For each taxi colour (yellow and green)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***i. What was the average, median, minimum and maximum trip duration in seconds?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('trip_duration',F.col(\"dropoff_date\").cast(\"long\") - F.col('pickup_date').cast(\"long\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT AVG(trip_duration) as average, percentile_approx(trip_duration, 0.5) as median, MIN(trip_duration) as minimum,MAX(trip_duration) as maximum , taxi_colour\n",
    "FROM combined_data\n",
    "GROUP BY taxi_colour\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+-----------+--------+-----------+\n",
      "|           average|median|    minimum| maximum|taxi_colour|\n",
      "+------------------+------+-----------+--------+-----------+\n",
      "|1263.6345686688685|   625|   -1437165|  202989|      green|\n",
      "| 995.1493983581707|   669|-2911502804|45466304|     yellow|\n",
      "+------------------+------+-----------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the average and median results appear reasonable, the minimum and maximum values appear to be flawed. Duration cannot be negative, and the maximum values are approximately 2 days and 526 days respectively. It is possible a taxi could have been rented for 2 days, however 526 days is highly unlikely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ii. What was the average, median, minimum and maximum trip distance in km?***\n",
    "The data dictionary states that the unit of measurement is a mile for trip distance. Value for conversion was retrieved from Googles 'unit converter', identified through the search term: \"km in miles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "miles_to_km = 1.60934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('distance_km', F.col('trip_distance')*miles_to_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT AVG(distance_km) as average, percentile_approx(distance_km, 0.5) as median, MIN(distance_km) as minimum,MAX(distance_km) as maximum , taxi_colour\n",
    "FROM combined_data\n",
    "GROUP BY taxi_colour\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+-------+------------------+-----------+\n",
      "|          average|            median|minimum|           maximum|taxi_colour|\n",
      "+-----------------+------------------+-------+------------------+-----------+\n",
      "| 4.66496505050157|2.9129053079128266|    0.0|12883.861334091796|      green|\n",
      "|4.718332105930787| 2.591037423021793|    0.0|  304943.929100625|     yellow|\n",
      "+-----------------+------------------+-------+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***iii. What was the average, median, minimum and maximum speed in km per hour?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('km_per_hour', F.col('distance_km')*3600/(F.col('trip_duration')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT AVG(km_per_hour) as average, percentile_approx(km_per_hour, 0.5) as median, MIN(km_per_hour) as minimum,MAX(km_per_hour) as maximum , taxi_colour\n",
    "FROM combined_data\n",
    "GROUP BY taxi_colour\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-------------------+--------------------+-----------+\n",
      "|           average|            median|            minimum|             maximum|taxi_colour|\n",
      "+------------------+------------------+-------------------+--------------------+-----------+\n",
      "| 22.55406684028411|17.743814347767223| -80.12458723404256|  194955.45644036864|      green|\n",
      "|21.121583492936892|15.872941883537365|-1004.6879889689855|1.6385046936749998E7|     yellow|\n",
      "+------------------+------------------+-------------------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. What was the percentage of trips where the driver received tips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('tip_received', F.col('tip_amount')>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT tip_received, count(tip_received) as tip,\n",
    "       count(tip_received) * 100.0 / (select count(*) from combined_data) as tip_percent\n",
    "FROM combined_data\n",
    "group by tip_received\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+-----------------+\n",
      "|tip_received|      tip|      tip_percent|\n",
      "+------------+---------+-----------------+\n",
      "|        true|149053314|62.93224115284405|\n",
      "|       false| 87793986|37.06775884715595|\n",
      "+------------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. For trips where the driver received tips, What was the percentage where the driver received tips of at least $10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('tip_received_over10', F.col('tip_amount')>=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\" SELECT tip_received_over10, count(tip_received_over10) as tip,\n",
    "       count(tip_received_over10) * 100.0 / (select count(*) from combined_data where tip_received = true) as tip_percent_over10\n",
    "FROM combined_data\n",
    "where tip_received = true\n",
    "group by tip_received_over10\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+------------------+\n",
      "|tip_received_over10|      tip|tip_percent_over10|\n",
      "+-------------------+---------+------------------+\n",
      "|               true|  4443013|  2.98082134557572|\n",
      "|              false|144610301| 97.01917865442428|\n",
      "+-------------------+---------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e. Classify each trip into bins\n",
    "***i. Average Speed***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Bucketizer\n",
    "bucketizer = Bucketizer(splits=[float('-Inf'),0,300,600,1200,1800,float('Inf') ],inputCol=\"trip_duration\", outputCol=\"trip_duration_bins\")\n",
    "df = bucketizer.setHandleInvalid(\"keep\").transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "t = {0:\"negative time - Invalid\",1.0:\"0-5 mins\", 2.0: \"5-10 mins\", 3.0:\"10-20 mins\", 4.0: \"20-30 mins\", 5.0: 'at least 30 mins'}\n",
    "convert_to_text = udf(lambda x: t[x], StringType())\n",
    "df=df.withColumn(\"trip_duration_bins_string\", convert_to_text(\"trip_duration_bins\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+----------+------------+------------+---------------+-------------+-----+-------+----------+------------+---------------------+------------+------------+-----------+-------------------+-------------------+-------------+------------------+------------------+------------------+-------------------------+\n",
      "|VendorID|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type|taxi_colour|        pickup_date|       dropoff_date|trip_duration|       distance_km|       km_per_hour|trip_duration_bins|trip_duration_bins_string|\n",
      "+--------+------------------+----------+------------+------------+---------------+-------------+-----+-------+----------+------------+---------------------+------------+------------+-----------+-------------------+-------------------+-------------+------------------+------------------+------------------+-------------------------+\n",
      "|       2|             false|         1|          66|          33|              5|         0.51|  0.5|    0.5|       0.7|         0.0|                  0.3|           6|           1|      green|2018-06-01 00:33:55|2018-06-01 00:36:13|          138|0.8207633846521377|21.411218730055765|               1.0|                 0-5 mins|\n",
      "|       2|             false|         1|          25|          49|              5|         1.97|  0.5|    0.5|      2.06|         0.0|                  0.3|       12.36|           1|      green|2018-06-01 00:40:36|2018-06-01 00:49:46|          550| 3.170399846043587|20.751708083194387|               2.0|                5-10 mins|\n",
      "|       2|             false|         1|          61|          49|              5|          1.4|  0.5|    0.5|       0.0|         0.0|                  0.3|         7.8|           2|      green|2018-06-01 00:57:12|2018-06-01 01:02:58|          346| 2.253075961630344| 23.44240884933306|               2.0|                5-10 mins|\n",
      "|       2|             false|         1|          49|          97|              1|         1.36|  0.5|    0.5|       0.0|         0.0|                  0.3|         8.3|           2|      green|2018-06-01 00:10:13|2018-06-01 00:16:27|          374|2.1887024230217933|21.067723857963784|               2.0|                5-10 mins|\n",
      "|       1|             false|         1|          75|         127|              1|          7.9|  0.5|    0.5|       6.3|         0.0|                  0.3|        31.6|           1|      green|2018-06-01 00:32:08|2018-06-01 00:52:06|         1198|12.713786153478623| 38.20503351629636|               3.0|               10-20 mins|\n",
      "+--------+------------------+----------+------------+------------+---------------+-------------+-----+-------+----------+------------+---------------------+------------+------------+-----------+-------------------+-------------------+-------------+------------------+------------------+------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"combined_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"SELECT AVG(km_per_hour), AVG(distance_km/total_amount), trip_duration_bins_string\n",
    "from combined_data\n",
    "group by trip_duration_bins_string\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------------------------------------+-------------------------+\n",
      "|   avg(km_per_hour)|avg((distance_km / CAST(total_amount AS DOUBLE)))|trip_duration_bins_string|\n",
      "+-------------------+-------------------------------------------------+-------------------------+\n",
      "| 16.994521521610128|                               0.2602294959362543|               10-20 mins|\n",
      "| 16.498508623452825|                               0.2152663797451226|                5-10 mins|\n",
      "| 20.461489266812094|                               0.3074613545115925|               20-30 mins|\n",
      "|-14.435587253389443|                               0.3066885786108011|     negative time - I...|\n",
      "|  24.05022920905049|                               0.3805705749984456|         at least 30 mins|\n",
      "|  38.65416235197026|                              0.17016166282864423|                 0-5 mins|\n",
      "+-------------------+-------------------------------------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Which duration bin will you advise a taxi driver to target to maximise his income?\n",
    "The lower the band generally correlates with the higher the income per km (or lower km per $). However, this does not take into account the wait times of "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
